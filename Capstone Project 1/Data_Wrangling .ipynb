{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Lending Club Data\n",
    "\n",
    "### Summary\n",
    "The purpose of this notebook is to clean raw Ledning Club data. This is the first part of a project aimed at creating a loan classification model for conservative investors in Lending Club.  The notebook shows the steps taken to prepare the raw Lending Club dataset for exploratory data analysis and machine learning. A brief summary of the content of this notebook is below:\n",
    "\n",
    "**Removing Extraneous Data**\n",
    "1. Removing columns with 100% missing values.\n",
    "2. Removing columns based on description that: \n",
    "    * Leaked information from the future.\n",
    "    * Contained redundant information.\n",
    "3. Removing columns with only one unique value.  \n",
    "\n",
    "**Preparing features for data exploration and machine learning**\n",
    "1. Preparing Categorical columns by:\n",
    "    * Mapping ordinal values to integers.\n",
    "    * Encoding nominal values as dummy variables.\n",
    "2. Removing percentage signs from continous data. \n",
    "3. Preparing the target column.\n",
    "4. Handling missing values by:\n",
    "    * Dropping rows with missing values under certain criteria.\n",
    "    * Imputing missing values using observations from data and a consevative mindset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant packages\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# importing the dataset\n",
    "loan_data = pd.read_csv('Loan_data.csv', low_memory=False, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (42538, 151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501        NaN     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430        NaN     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175        NaN     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863        NaN    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358        NaN     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade       ...        \\\n",
       "0   10.65%       162.87     B        B2       ...         \n",
       "1   15.27%        59.83     C        C4       ...         \n",
       "2   15.96%        84.33     C        C5       ...         \n",
       "3   13.49%       339.31     C        C1       ...         \n",
       "4   12.69%        67.79     B        B5       ...         \n",
       "\n",
       "  hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "\n",
       "  disbursement_method  debt_settlement_flag debt_settlement_flag_date  \\\n",
       "0                Cash                     N                       NaN   \n",
       "1                Cash                     N                       NaN   \n",
       "2                Cash                     N                       NaN   \n",
       "3                Cash                     N                       NaN   \n",
       "4                Cash                     N                       NaN   \n",
       "\n",
       "  settlement_status settlement_date settlement_amount settlement_percentage  \\\n",
       "0               NaN             NaN               NaN                   NaN   \n",
       "1               NaN             NaN               NaN                   NaN   \n",
       "2               NaN             NaN               NaN                   NaN   \n",
       "3               NaN             NaN               NaN                   NaN   \n",
       "4               NaN             NaN               NaN                   NaN   \n",
       "\n",
       "  settlement_term  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))\n",
    "\n",
    "# viewing the first few columns of the dataset\n",
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see the dataset has 42538 rows and 151 columns. Not all of this data will be useful for the intended loan classification analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Extraneous Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns with 100% missing values**\n",
    "\n",
    "These columns contain no information and will not be useful for any analysis. Consequently, these columns are removed from the dataset in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (42538, 69)\n"
     ]
    }
   ],
   "source": [
    "# Removing columns with 100% missing values\n",
    "loan_data = loan_data.dropna(how = 'all', axis = 1)\n",
    "\n",
    "# print the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the removal, there are 69 columns left in the dataset, indicating that 82 columns were initially empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing columns based on descriptions**\n",
    "\n",
    "All the remaining columns in the dataset are reviewed based on descriptions found in the [Lending Club Data Dictionary](https://resources.lendingclub.com/LCDataDictionary.xlsx). Columns which provide information an investor will not have at the time he/she is deciding whether to make an investment (leaks information from the future) are removed from the dataset. Additionally, columns which contain information that is not useful for loan classification (e.g url and member id columns) are also removed. \n",
    "\n",
    "The names of the 69 columns left in the dataset are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
       "       'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
       "       'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title',\n",
       "       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n",
       "       'fico_range_low', 'fico_range_high', 'inq_last_6mths',\n",
       "       'mths_since_last_delinq', 'mths_since_last_record', 'open_acc',\n",
       "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
       "       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
       "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
       "       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
       "       'last_fico_range_high', 'last_fico_range_low',\n",
       "       'collections_12_mths_ex_med', 'policy_code', 'application_type',\n",
       "       'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt',\n",
       "       'pub_rec_bankruptcies', 'tax_liens', 'hardship_flag',\n",
       "       'disbursement_method', 'debt_settlement_flag',\n",
       "       'debt_settlement_flag_date', 'settlement_status', 'settlement_date',\n",
       "       'settlement_amount', 'settlement_percentage', 'settlement_term'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying names of columns in the dataset\n",
    "loan_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above list, the columns not needed are listed below with a breif description of why.\n",
    "1. id - a random unique identifier created by Lending Club not useful for analysis\n",
    "2. funded_amnt - leaks information from the future (amount funded)\n",
    "3. funded_amnt_inv - leaks information from the future (amount investors funded)\n",
    "4. issue_d - leaks information from the future (month which loan was funded)\n",
    "5. url - does not provide useful information\n",
    "6. zip_code - only first 3 letters of zipcode given, provides the same information as addr_state \n",
    "7. out_prncp - leaks data from the future (outstanding principal)\n",
    "8. out_prncp_inv - leaks data from the future (outstanding principal investors portion of fund)\n",
    "9. total_pymnt - leaks data from the future (payments received to date on loan funded)\n",
    "10. total_pymnt_inv - leaks data from the future (payments received to date on loan funded)\n",
    "11. total_rec_prncp - leaks information from the future (principal received to date)\n",
    "12. total_rec_int - leaks information from the future (interest received to date)\n",
    "13. total_rec_late_feev- leaks information from the future (recovered late fees)\n",
    "14. recoveries - leaks information from the future (post charge off gross recoveries)\n",
    "15. collection_recovery_fee - leaks information from the future (post charge off collection fee)\n",
    "16. last_pymnt_d - leaks information from the future (date last payment was received)\n",
    "17. last_pymnt_amnt - leaks information from the future (most recent payment amount)\n",
    "18. last_credit_pull_d - leaks information from the future (date last credit was pulled by LC)\n",
    "19. last_fico_range_high - leaks information from the future (highest FICO score in most recent credit pull)\n",
    "20. last_fico_range_low - leaks infromation from the future (lowest FICO score in most recent credit pull)\n",
    "21. debt_settlement_flag - leaks information from the future (settlement of debt following inability to pay)\n",
    "22. debt_settlement_flag_date - leaks information from the future (date of debt settlement flag)\n",
    "23. settlement_date - leaks information from the future (date of settlement)\n",
    "24. settlement_status - leaks information from the future (status of debt settlement)\n",
    "25. settlement_amount - leaks information from the future (amount to be paid for debt settlement)\n",
    "26. settlement_percentage - leaks information from the future (settlement amount as percentage of unpaid debt)\n",
    "27. settlement_term - leaks information from the future (time over which settlement is to be paid)\n",
    "28. hardship_flag - leaks information from the future (indicates borrowers facing difficulties repaying loans)\n",
    "29. next_pymnt_d - leaks information from the future (provides information on loans funded\n",
    "30. chargeoff_within_12_mths - leaks information from the future (provides information on early defaulters)\n",
    "31. grade - it provides the same information as subgrade but in fewer categories\n",
    "\n",
    "\n",
    "NOTE: while issue_d is on this list, it will not be dropped immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of the columns listed above \n",
    "cols_to_drop = ['id', 'funded_amnt', 'funded_amnt_inv', 'url', 'grade',\n",
    "                'zip_code', 'out_prncp', 'out_prncp_inv', 'total_pymnt', \n",
    "                'total_pymnt_inv', 'total_rec_prncp', 'debt_settlement_flag',\n",
    "                'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
    "                'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d',\n",
    "                'last_fico_range_high', 'last_fico_range_low', 'total_rec_int',\n",
    "                'debt_settlement_flag_date', 'settlement_date', \n",
    "                'settlement_status', 'settlement_amount', 'settlement_term',\n",
    "                'settlement_percentage', 'hardship_flag', 'next_pymnt_d', \n",
    "                'chargeoff_within_12_mths']\n",
    " \n",
    "# dropping the columns listed above  \n",
    "loan_data = loan_data.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptions alone were not enough to decide whether to drop certain columns. The columns listed below require further investigation to decide how to deal with them:\n",
    "* fico_range_high and fico_range_low\n",
    "* purpose and title \n",
    "* earliest_cr_line and issue_d\n",
    "\n",
    "**FICO score columns:** The fico_range_high and fico_range_low columns display represent the region within which a borrower's FICO score is in. There are 44 unique ranges. Having the range values in two columns is inefficient as the average of the range can be used to form one categorical column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the fico_average column\n",
    "loan_data['fico_average'] = (loan_data['fico_range_high'] + loan_data['fico_range_low'])/2\n",
    "\n",
    "# dropping the fico range columns \n",
    "loan_data = loan_data.drop(['fico_range_low','fico_range_high'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose and title columns:** The purpose and tilte columns are both provided by the borrower. The purpose column contains categorical information on the purpose of the loan while the title column contains the name the borrower assigns the loan. These two columns contain the very similar information however, the purpose column is better categorized (as shown below). For this reason, the title column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the purpose column: 14\n",
      "Number of unique values in the title column: 21264\n"
     ]
    }
   ],
   "source": [
    "# printing the number of unique values in each column\n",
    "print('Number of unique values in the purpose column: ' + str(loan_data['purpose'].nunique()))\n",
    "print('Number of unique values in the title column: ' + str(loan_data['title'].nunique()))\n",
    "\n",
    "# dropping the title column\n",
    "loan_data = loan_data.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Earliest Credit line:** An important feature when determining credit scores is the age of the oldest account. For this reason, the earliest_cr_line column will be engineered to estimate the age of each borrowers oldest account. This will be achieved by calculating the difference between the month which a loan was funded (issue_d) and the borrower's earliest credit line (earliest_cr_line). It is a reasonable approximation as it provides a good estimate of the age of credit line an investor will see when deciding whether to invest in the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the earliest credit line column to datetime\n",
    "loan_data['earliest_cr_line']= pd.to_datetime(loan_data['earliest_cr_line'])\n",
    "\n",
    "# converting the loan issue date column to datetime\n",
    "loan_data['issue_d'] = pd.to_datetime(loan_data['issue_d'])\n",
    "\n",
    "# estimating the age of the oldest credit line\n",
    "loan_data['age_cr_line'] = loan_data['issue_d']- loan_data['earliest_cr_line'] \n",
    "\n",
    "# dropping the earliest credit line and loan issue date columns\n",
    "loan_data = loan_data.drop(['earliest_cr_line', 'issue_d'], axis =1)\n",
    "\n",
    "# converting from time delta to numeric type\n",
    "loan_data['age_cr_line'] = loan_data['age_cr_line'].dt.days\n",
    "\n",
    "# converting age of credit line from days to months\n",
    "days_in_month = 30.4375\n",
    "loan_data['age_cr_line'] = round(loan_data['age_cr_line']/days_in_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (42538, 36)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing columns with one unique value**\n",
    "\n",
    "Following the review of each description, there are 36 columns left in the dataset. In this section, columns that have only one unique value are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (42538, 30)\n"
     ]
    }
   ],
   "source": [
    "# removing columns with only one unique value \n",
    "loan_data = loan_data.loc[:,loan_data.apply(func=pd.Series.nunique, args=(False)) > 1]\n",
    "\n",
    "# printing the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 30 columns remaining. The name of these columns are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'term', 'int_rate', 'installment', 'sub_grade',\n",
       "       'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n",
       "       'verification_status', 'loan_status', 'desc', 'purpose', 'addr_state',\n",
       "       'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq',\n",
       "       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'acc_now_delinq', 'delinq_amnt',\n",
       "       'pub_rec_bankruptcies', 'tax_liens', 'fico_average', 'age_cr_line'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying name of remaining columns\n",
    "loan_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing features for data exploration and machine learning\n",
    "\n",
    "### Wrangling Categorical columns\n",
    "\n",
    "**Categorizing the employer title column**\n",
    "\n",
    "As fully categorizing the employer title column will be significant work, only some of the most common or popular employer titles are categorized. The categories used include:\n",
    "1. No response\n",
    "2. Unemployed\n",
    "3. Self employed\n",
    "4. Educational and Reserch Institutions\n",
    "5. US Military \n",
    "6. Big Financial Services\n",
    "7. Technology Companies (FAANG)\n",
    "8. Other employers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uncategorized employer      34107\n",
       "Educational Institutions     2641\n",
       "No response                  2629\n",
       "Big Financial Services        993\n",
       "US Military                   947\n",
       "Major Retailers               819\n",
       "self_employed                 231\n",
       "Tech companies (FAANG)        113\n",
       "unemployed                     58\n",
       "Name: emp_title_cat, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a function to categorize employrt title\n",
    "def employer_categorizer(emp_title):\n",
    "    \n",
    "    # creating a placeholder for the category\n",
    "    category = int()\n",
    "    \n",
    "    try:\n",
    "        # creating a list of unemployed/employed words\n",
    "        unemploy = [\"unemploy\", 'retired', 'un-employ', 'un employ']\n",
    "        \n",
    "        # check if unemployed\n",
    "        if any(word in emp_title.lower() for word in unemploy):\n",
    "            if any('retirement' in emp_title.lower() for word in unemploy):\n",
    "                category = emp_title\n",
    "            else:\n",
    "                category = 'unemployed'\n",
    "            \n",
    "        # check if self-employed\n",
    "        elif \"self\" in emp_title.lower():\n",
    "            \n",
    "            # some key words attached to self that may not be self-employed\n",
    "            not_self_emp = ['storage', 'housing', 'elderly']\n",
    "            \n",
    "            if any(word in emp_title.lower() for word in not_self_emp):\n",
    "                category = emp_title\n",
    "             \n",
    "            else:\n",
    "                category = 'self_employed'\n",
    "        \n",
    "        # checking for other job categories\n",
    "        if (category != 'self_employed') & (category != 'unemployed'):\n",
    "            \n",
    "            # list of words for military related employer title\n",
    "            US_military = [\"usaf\", 'army', \"air force\", \"marine corps\", \"patrol\", \"navy\",\n",
    "                           \"military\", \"usmc\", \"coast guard\"]\n",
    "            \n",
    "            # list of words for big financial services related work (big  investment/accounting/consulting)\n",
    "            Financial_services = [\"bank of america\", \"jp\", \"chase\", \"wells\", \"morgan\", 'deloitte',\n",
    "                                  \"fidelity\", \"american express\", \"lynch\",\"hsbc\", \"barclays\",\n",
    "                                  \"capital one\", 'kpmg',\"schwab\", 'pricewater', 'arthur anderson' \n",
    "                                  'goldman',\"accenture\", \"bcg\", \"boston consulting\", \"ernst\",\n",
    "                                  \"bain\", 'mc kinsey', 'mckinsey']\n",
    "            \n",
    "            # list of words for telecommunications/tech related \n",
    "            Big_tech = ['facebook', 'fb', 'google', 'alphabet', 'netflix', 'apple', 'amazon']\n",
    "            \n",
    "            # list of words for educational/health related services\n",
    "            Education = ['college', 'university', 'school', 'education','ucsf', 'institute',\n",
    "                         'research']\n",
    "            # big retailers\n",
    "            Big_retailers =  ['walmart', 'walgreens', 'target', 'cvs', 'best buy',  'safeway',\n",
    "                              'depot', 'nordstrom', 'costco', 'wal-mart', 'rite aid', 'staples', \n",
    "                              'macy\\'s', 'macy', 'kroger', 'albertson', 'nordstrom', 'lowe\\'s', \n",
    "                              'kohl', 'aldi', 'publix']\n",
    "\n",
    "            \n",
    "            # check if borrower works in the US military\n",
    "            if any(employer in emp_title.lower() for employer in US_military):\n",
    "                category = 'US Military' \n",
    "            \n",
    "            # check if borrower works in financial/consulting services\n",
    "            elif any(employer in emp_title.lower() for employer in Financial_services):\n",
    "                category = 'Big Financial Services'\n",
    "            \n",
    "            # check if borrower works in telecommunications\n",
    "            elif any(employer in emp_title.lower() for employer in Big_tech):\n",
    "                category = 'Tech companies (FAANG)'\n",
    "            \n",
    "            # check if employer works in education\n",
    "            elif any(employer in emp_title.lower() for employer in Education):\n",
    "                category = 'Educational Institutions'\n",
    "            \n",
    "            # check if employer works in education\n",
    "            elif any(employer in emp_title.lower() for employer in Big_retailers):\n",
    "                category = 'Major Retailers'\n",
    "        \n",
    "            else:\n",
    "                category = 'Uncategorized employer'\n",
    "               \n",
    "    except Exception:\n",
    "        # check if no response\n",
    "        if math.isnan(emp_title):\n",
    "            category = 'No response'\n",
    "    \n",
    "    return category\n",
    "\n",
    "# creating categorical employer title columns\n",
    "loan_data['emp_title_cat'] = loan_data.emp_title.apply(employer_categorizer)\n",
    "\n",
    "# dropping the employer_title column\n",
    "loan_data = loan_data.drop(['emp_title'], axis =1)\n",
    "\n",
    "# viewing the results \n",
    "loan_data['emp_title_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorizing the loan description column**\n",
    "\n",
    "A proper categorization of the loan description column will require natural language processing. However, for this project a simple classification will be done based on the borrowers that provided a description and the borrowers that did not. The categories used are shown below. \n",
    "* 0: No response\n",
    "* 1: Description provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_categorizer(description):\n",
    "    \n",
    "    # creating a placeholder for categort\n",
    "    category = int()\n",
    "    \n",
    "    # check if response was not provided\n",
    "    try:\n",
    "        message = description.lower()\n",
    "        category = 1\n",
    "    \n",
    "    except Exception:\n",
    "        category = 0\n",
    "    \n",
    "    return category\n",
    "\n",
    "# creating categorical description columns\n",
    "loan_data['desc_cat'] = loan_data['desc'].apply(response_categorizer)\n",
    "\n",
    "# dropping the employer_title column\n",
    "loan_data = loan_data.drop(['desc'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using ordinal values to categorize the employment length and sub grade columns**\n",
    "\n",
    "The employment length and subgrade columns are converted to numeric type for data exploration and machine learning. For the employment length column, 10 or more years of employment is categorized 10 years of employment, while the \"n/a\" responses and responses indicating less than 1 year of experience are categorized as 0 years of employment. \n",
    "\n",
    "The maps for the employment and sub grade columns are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mapping dictionart for the sub_grade column\n",
    "ranked_sub_grade = loan_data.sub_grade.value_counts().sort_index().index.tolist()\n",
    "sub_grade_map = {sub_grade:(index+1) for index, sub_grade in enumerate(ranked_sub_grade)}\n",
    "\n",
    "# Map for the employment length column\n",
    "mapping_dict = {\"emp_length\": {\n",
    "                               \"10+ years\": 10,\n",
    "                               \"9 years\": 9,\n",
    "                               \"8 years\": 8,\n",
    "                               \"7 years\": 7,\n",
    "                               \"6 years\": 6,\n",
    "                               \"5 years\": 5,\n",
    "                               \"4 years\": 4,\n",
    "                               \"3 years\": 3,\n",
    "                               \"2 years\": 2,\n",
    "                               \"1 year\": 1,\n",
    "                               \"< 1 year\": 0,\n",
    "                               \"n/a\": 0\n",
    "                               },\n",
    "                \"sub_grade\": sub_grade_map\n",
    "               }\n",
    "               \n",
    "\n",
    "\n",
    "# converting the columns\n",
    "loan_data = loan_data.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using dummy columns to categorize the nominal variables**\n",
    "\n",
    "Since nominal variables cannot be ranked, dummy columns will be made to categorize them. This code for this is shown below for the columns: \"home_ownership\", \"verification_status\", \"purpose\", \"term\" and \"emp_title_cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of nominal columns\n",
    "nominal_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\", \n",
    "                   \"emp_title_cat\"]\n",
    "\n",
    "# creating dummy columns \n",
    "dummy_df = pd.get_dummies(loan_data[nominal_columns], drop_first = True)\n",
    "\n",
    "# concatenating the columns to loan_data dataframe\n",
    "loan_data = pd.concat([loan_data, dummy_df], axis=1)\n",
    "\n",
    "# dropping the nominal columns\n",
    "loan_data = loan_data.drop(nominal_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addr_state column contains too many nominal variables. For this reason, the states are categorixed based on the region of the country it is in (West, Midwest, Northeast and South). Subsequently, dummy columns are made for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of states with more than 420 borrowers  \n",
    "state_count = loan_data['addr_state'].value_counts()\n",
    "top_counts = state_count[state_count>420]\n",
    "top_states = top_counts.index.tolist()\n",
    "\n",
    "# creating a function to categorize states by region\n",
    "def state_categorizer(states):\n",
    "    \n",
    "    # making lists of states and Washington DC  by region\n",
    "    West = [\"CA\", \"OR\", \"NV\", \"WA\", \"ID\", \"UT\", \"AZ\", \"NM\", \"CO\", \"WY\", \"MT\", \n",
    "            \"AK\",\"HI\"]\n",
    "    Midwest = [\"MD\", \"MN\", \"WY\", \"SD\", \"NE\", \"KS\", \"MO\", \"IA\", \"WI\", \"IL\", \"MI\",\n",
    "               \"IN\", \"OH\"]\n",
    "    Northeast = [\"ME\", \"NH\", \"VT\", 'PA', \"CT\", \"NY\", \"MA\", \"CT\", \"NJ\", \"RI\"]\n",
    "    South = [\"TX\", \"OK\", \"AR\", \"LA\", \"MS\", \"AL\", \"TN\", \"KY\", \"GA\", \"FL\", \"SC\"\n",
    "             \"NC\", \"VA\", \"WV\", \"DC\", \"MD\", \"DE\"]\n",
    "      \n",
    "    try: \n",
    "    # check which category state belongs to\n",
    "        if any(state in states for state in top_states):\n",
    "            category  = states\n",
    "        elif any(state in states for state in West):\n",
    "            category = 'West'\n",
    "        elif any(state in states for state in Midwest):\n",
    "            category = 'Midwest'\n",
    "        elif any(state in states for state in South):\n",
    "            category = 'South'\n",
    "        elif any(state in states for state in Northeast):\n",
    "            category = 'Northeast'\n",
    "        else:\n",
    "            category = 'uncategorized'\n",
    "        \n",
    "    except Exception:\n",
    "            category = 'no response'\n",
    "    \n",
    "    return category\n",
    "\n",
    "# creating categorical employer title columns\n",
    "loan_data['categorized_states'] = loan_data.addr_state.apply(state_categorizer)\n",
    "\n",
    "# making dummy region columns\n",
    "dummy_region = pd.get_dummies(loan_data['categorized_states'], drop_first = True)\n",
    "\n",
    "# concatenating the columns to loan_data dataframe\n",
    "loan_data = pd.concat([loan_data, dummy_region], axis=1)\n",
    "\n",
    "# dropping the region and addr_state columns\n",
    "loan_data = loan_data.drop(['addr_state', 'categorized_states'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the reovolving utililization and interest rate columns\n",
    "\n",
    "The revolving utilization and interest rate columns have percentage signs in front of them that need to be removed for analysis. This is done in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the interest rate and revolving utilization columns to float\n",
    "loan_data[\"int_rate\"] = loan_data[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loan_data[\"revol_util\"] = loan_data[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the target column\n",
    "The target column for loan classification is the loan_status column. A quick look at the variables and their respective counts in the loan_status column is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             34116\n",
       "Charged Off                                             5670\n",
       "Does not meet the credit policy. Status:Fully Paid      1988\n",
       "Does not meet the credit policy. Status:Charged Off      761\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing variables and count\n",
    "loan_data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Lendinc Club, loans of the type which does not meet their credit policy will no more be offered to investors. Consequently, these columns will be discarded and the remaining rows will be categorized such that:\n",
    "* Fully Paid: 1\n",
    "* Charged Off: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (39786, 82)\n"
     ]
    }
   ],
   "source": [
    "# removing rows that do not meet Lending Club's credit policy\n",
    "loan_data = loan_data[(loan_data['loan_status'] == 'Fully Paid')|\n",
    "                       (loan_data['loan_status'] == 'Charged Off')]\n",
    "\n",
    "# converting loan_status to numerical values where 1 represents paid and 0 represents charged off \n",
    "loan_data['loan_status'] = loan_data[['loan_status']].replace({'Fully Paid':1, 'Charged Off':0})\n",
    "\n",
    "# printing the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 112 columns. Reducing the number of rows may have affected the number of unique values in some columns. Once again the columns with only one unique value are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (39786, 78)\n"
     ]
    }
   ],
   "source": [
    "# removing columns with only one unique value \n",
    "loan_data = loan_data.loc[:,loan_data.apply(func=pd.Series.nunique, args=(False)) > 1]\n",
    "\n",
    "# printing the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "With the categorical columns prepared, missing values will now be handled. Below we take a look at the missing values count in columns with missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_length                 1078\n",
       "mths_since_last_delinq    25727\n",
       "mths_since_last_record    36995\n",
       "revol_util                   50\n",
       "pub_rec_bankruptcies        697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of missing values\n",
    "null_counts = loan_data.isnull().sum()\n",
    "\n",
    "# displaying results \n",
    "null_counts[null_counts != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy for handling missing revolving utilization missing values:**\n",
    "* There are 50 rows with missing data in the revolving utilization column. This represents less than 1% (398 rows) of the rows in the data. Since these rows are few and difficult to predict, they will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_length                 1075\n",
       "mths_since_last_delinq    25690\n",
       "mths_since_last_record    36947\n",
       "pub_rec_bankruptcies        697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with missing values in revol_util\n",
    "loan_data = loan_data[pd.notnull(loan_data['revol_util'])]\n",
    "\n",
    "# displaying results for the missing values\n",
    "null_counts = loan_data.isnull().sum()\n",
    "null_counts[null_counts != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that dropping these rows did not affect the number of unique values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (39736, 78)\n"
     ]
    }
   ],
   "source": [
    "# removing columns with only one unique value \n",
    "loan_data = loan_data.loc[:,loan_data.apply(func=pd.Series.nunique, args=(False)) > 1]\n",
    "\n",
    "# printing the size of the dataset\n",
    "print('The size of the dataset: ' + str(loan_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still 107 columns. Next, the missing values of the employment length column and public record bankruptcies column are dealt with. \n",
    "\n",
    "**Strategy for handling employment length missing values:**\n",
    "* Borrowers that did not provide their employment length and employment title will be assumed to be unemployed. \n",
    "* Borrowers that did not provide their employment length are unemployed/retired will be assigned an employment length of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Borrowers with no employment length or title: 1019\n",
      "Count of borrowers with no employment length and unemployed: 2\n",
      "\n",
      " The new frequency of missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emp_length                   54\n",
       "mths_since_last_delinq    25690\n",
       "mths_since_last_record    36947\n",
       "pub_rec_bankruptcies        697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# borrowers with no employment length or title data\n",
    "no_el_no_title = loan_data[(pd.isnull(loan_data['emp_length'])) & \n",
    "                        (loan_data['emp_title_cat_No response'] == 1)]\n",
    "\n",
    "print('Count of Borrowers with no employment length or title: '\n",
    "          + str(len(no_el_no_title)))\n",
    "\n",
    "# borrowers with no employment length but unemployed title \n",
    "no_el_unemp_title = loan_data[(pd.isnull(loan_data['emp_length'])) & \n",
    "                        (loan_data['emp_title_cat_unemployed'] == 1)]\n",
    "\n",
    "print('Count of borrowers with no employment length and unemployed: ' + \n",
    "      str(len(no_el_unemp_title)))\n",
    "\n",
    "'''creating a function that converts missing values in the employment\n",
    "length column to 0 under certain constraints'''\n",
    "def emp_length_converter(row):\n",
    "    \n",
    "    #borrowers with no employment length and title data\n",
    "    if (math.isnan(row['emp_length'])) & (row['emp_title_cat_No response'] ==1):\n",
    "        value = 0\n",
    "        \n",
    "    #borrowers with no employment length and unemployed\n",
    "    elif (math.isnan(row['emp_length'])) & (row['emp_title_cat_unemployed'] ==1):\n",
    "          value = 0\n",
    "    \n",
    "    else:\n",
    "          value = row['emp_length']\n",
    "          \n",
    "    return value\n",
    "          \n",
    "loan_data['emp_length'] = loan_data.apply(emp_length_converter, axis=1)\n",
    "        \n",
    "# displaying results for the missing values\n",
    "print(\"\\n The new frequency of missing values:\")\n",
    "null_counts = loan_data.isnull().sum()\n",
    "null_counts[null_counts != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing values in the employment length column has been reduced from 1075 to 54. As this values are few and we are aware these borrowers have jobs, imputation will be used to assign the remaining employment lengths. It is important to remember that the end goal of preparing this dataset is to build a loan classification model for a conservative investor. Consequently, it will be assumed that the remaining 54 borrowers with missing employment length have the equivalent of 0 years of experiecne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mths_since_last_delinq    25690\n",
       "mths_since_last_record    36947\n",
       "pub_rec_bankruptcies        697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling in the missing values with the median\n",
    "loan_data['emp_length'] = loan_data['emp_length'].fillna(0)\n",
    "\n",
    "# displaying results of missing values\n",
    "null_counts = loan_data.isnull().sum()\n",
    "null_counts[null_counts != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy for handling public record bankruptcies**\n",
    "* A correlation matrix will be made and the variables that strongly correlate with public recorded bankruptcies will be identified.\n",
    "* These variables will be used to predict what the missing entries are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pub_rec_bankruptcies      1.000000\n",
       "pub_rec                   0.845979\n",
       "mths_since_last_record    0.823750\n",
       "fico_average              0.130303\n",
       "int_rate                  0.082816\n",
       "Name: pub_rec_bankruptcies, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a correlation matrix  using the loan dataset\n",
    "corr_matrix = loan_data.corr()\n",
    "\n",
    "# selecting the column with count of public record bankruptcies\n",
    "PBR_corr = corr_matrix['pub_rec_bankruptcies']\n",
    "\n",
    "# sorting the values  \n",
    "PBR_sorted = PBR_corr.abs().sort_values(ascending = False)\n",
    "\n",
    "PBR_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>OH</th>\n",
       "      <th>OR</th>\n",
       "      <th>PA</th>\n",
       "      <th>SC</th>\n",
       "      <th>South</th>\n",
       "      <th>TX</th>\n",
       "      <th>VA</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "      <th>West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [loan_amnt, int_rate, installment, sub_grade, emp_length, annual_inc, loan_status, dti, delinq_2yrs, inq_last_6mths, mths_since_last_delinq, mths_since_last_record, open_acc, pub_rec, revol_bal, revol_util, total_acc, pub_rec_bankruptcies, fico_average, age_cr_line, desc_cat, home_ownership_NONE, home_ownership_OTHER, home_ownership_OWN, home_ownership_RENT, verification_status_Source Verified, verification_status_Verified, purpose_credit_card, purpose_debt_consolidation, purpose_educational, purpose_home_improvement, purpose_house, purpose_major_purchase, purpose_medical, purpose_moving, purpose_other, purpose_renewable_energy, purpose_small_business, purpose_vacation, purpose_wedding, term_ 60 months, emp_title_cat_Educational Institutions, emp_title_cat_Major Retailers, emp_title_cat_No response, emp_title_cat_Tech companies (FAANG), emp_title_cat_US Military, emp_title_cat_Uncategorized employer, emp_title_cat_self_employed, emp_title_cat_unemployed, AZ, CA, CO, CT, FL, GA, IL, LA, MA, MD, MI, MN, MO, Midwest, NC, NJ, NV, NY, Northeast, OH, OR, PA, SC, South, TX, VA, WA, WI, West]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 78 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if any borrower that doesn't have a public record has a bankruptcy record\n",
    "loan_data[(loan_data['pub_rec_bankruptcies'] > 0)&(loan_data['pub_rec'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside public records, no other variables correlate strongly with public record bankruptcies. It is also worth noting that in the dataset every borrower without a public derogatory record does not have a public record bankruptcy. Taking a conservative approach, it will be assumed that:\n",
    "1. Any borrower with a public derogatory record that did not provide a response to the number public recorded bankruptcies, also has a public recorded bankruptcy.\n",
    "2. Every borrower that does not have a public derogatorty record and did not provide a response to the number of public record bankruptcies, does not have a public record bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to predict missing public recorded bankruptcy\n",
    "\n",
    "def bankruptcy_maker(row):\n",
    "    \n",
    "    value = float()\n",
    "    \n",
    "    if (row['pub_rec'] > 0) & (math.isnan(row['pub_rec_bankruptcies'])):\n",
    "        value = 1\n",
    "    elif (row['pub_rec'] == 0) & (math.isnan(row['pub_rec_bankruptcies'])):\n",
    "        value = 0\n",
    "    else:\n",
    "        value = row['pub_rec_bankruptcies']\n",
    "    return value \n",
    "\n",
    "loan_data['pub_rec_bankruptcies'] = loan_data.apply(bankruptcy_maker, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A check to verify there are no missing values in the public_record_bankruptcies column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mths_since_last_delinq    25690\n",
       "mths_since_last_record    36947\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying results of missing values\n",
    "null_counts = loan_data.isnull().sum()\n",
    "null_counts[null_counts != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorizing the months since last delinquency and months since last record columns**\n",
    "\n",
    "Due to the large number of missing values the last two columns will be categorized in a manner similar to the loan description columns. \n",
    "* 0: No response\n",
    "* 1: Response provided\n",
    "\n",
    "To this end, the response categorizer function will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating categorical description columns\n",
    "loan_data['mths_since_last_delinq'] = loan_data['mths_since_last_delinq'].apply(response_categorizer)\n",
    "loan_data['mths_since_last_record'] = loan_data['mths_since_last_record'].apply(response_categorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final check to verify there are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying results of missing values\n",
    "null_counts = loan_data.isnull().sum()\n",
    "null_counts[null_counts != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready for exploration and machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting data\n",
    "loan_data.to_csv('Wrangled_Loan_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
